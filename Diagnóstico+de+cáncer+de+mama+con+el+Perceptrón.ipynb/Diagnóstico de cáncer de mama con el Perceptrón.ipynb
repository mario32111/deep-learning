{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caso Práctico: Neurona de McCulloch y Pitts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Aplicando la MPNeuron a un caso práctico real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Conjunto de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta es una copia de los conjuntos de datos de UCI ML Breast Cancer Wisconsin (Diagnóstico). https://goo.gl/U2Uwz2\n",
    "\n",
    "Las características de entrada se calculan a partir de una imagen digitalizada de un aspirado de aguja fina (FNA) de una masa mamaria. Describen las características de los núcleos celulares presentes en la imagen.\n",
    "\n",
    "El plano de separación descrito anteriormente se obtuvo utilizando el método de árbol de múltiples superficies (MSM-T) [K. P. Bennett, \"Construcción de un árbol de decisión mediante programación lineal\". Proceedings of the 4th Midwest Artificial Intelligence and Cognitive Science Society, pp. 97-101, 1992], un método de clasificación que utiliza la programación lineal para construir un árbol de decisión. Los rasgos relevantes se seleccionaron mediante una búsqueda exhaustiva en el espacio de 1-4 rasgos y 1-3 planos de separación.\n",
    "\n",
    "El programa lineal real utilizado para obtener el plano de separación en el espacio tridimensional es el que se describe en: [K. P. Bennett y O. L. Mangasarian: \"Robust Linear Programming Discrimination of Two Linearly Inseparable Sets\", Optimization Methods and Software 1, 1992, 23-34].\n",
    "\n",
    "Esta base de datos también está disponible a través del servidor ftp UW CS:\n",
    "\n",
    "ftp ftp.cs.wisc.edu cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
    "\n",
    "### Referencias\n",
    "\n",
    "* W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on Electronic Imaging: Science and Technology, volume 1905, pages 861-870, San Jose, CA, 1993.\n",
    "* O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and prognosis via linear programming. Operations Research, 43(4), pages 570-577, July-August 1995.\n",
    "* W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) 163-171."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Lectura del conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "breast_cancer = load_breast_cancer()\n",
    "\n",
    "X = breast_cancer.data\n",
    "Y = breast_cancer.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DESCR',\n",
       " 'data',\n",
       " 'data_module',\n",
       " 'feature_names',\n",
       " 'filename',\n",
       " 'frame',\n",
       " 'target',\n",
       " 'target_names']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(breast_cancer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "        1.189e-01],\n",
       "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "        8.902e-02],\n",
       "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "        8.758e-02],\n",
       "       ...,\n",
       "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "        7.820e-02],\n",
       "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "        1.240e-01],\n",
       "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "        7.039e-02]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Visualización del conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
       "0                   0.07871  ...        25.380          17.33   \n",
       "1                   0.05667  ...        24.990          23.41   \n",
       "2                   0.05999  ...        23.570          25.53   \n",
       "3                   0.09744  ...        14.910          26.50   \n",
       "4                   0.05883  ...        22.540          16.67   \n",
       "..                      ...  ...           ...            ...   \n",
       "564                 0.05623  ...        25.450          26.40   \n",
       "565                 0.05533  ...        23.690          38.25   \n",
       "566                 0.05648  ...        18.980          34.12   \n",
       "567                 0.07016  ...        25.740          39.42   \n",
       "568                 0.05884  ...         9.456          30.37   \n",
       "\n",
       "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       "0             184.60      2019.0           0.16220            0.66560   \n",
       "1             158.80      1956.0           0.12380            0.18660   \n",
       "2             152.50      1709.0           0.14440            0.42450   \n",
       "3              98.87       567.7           0.20980            0.86630   \n",
       "4             152.20      1575.0           0.13740            0.20500   \n",
       "..               ...         ...               ...                ...   \n",
       "564           166.10      2027.0           0.14100            0.21130   \n",
       "565           155.00      1731.0           0.11660            0.19220   \n",
       "566           126.70      1124.0           0.11390            0.30940   \n",
       "567           184.60      1821.0           0.16500            0.86810   \n",
       "568            59.16       268.6           0.08996            0.06444   \n",
       "\n",
       "     worst concavity  worst concave points  worst symmetry  \\\n",
       "0             0.7119                0.2654          0.4601   \n",
       "1             0.2416                0.1860          0.2750   \n",
       "2             0.4504                0.2430          0.3613   \n",
       "3             0.6869                0.2575          0.6638   \n",
       "4             0.4000                0.1625          0.2364   \n",
       "..               ...                   ...             ...   \n",
       "564           0.4107                0.2216          0.2060   \n",
       "565           0.3215                0.1628          0.2572   \n",
       "566           0.3403                0.1418          0.2218   \n",
       "567           0.9387                0.2650          0.4087   \n",
       "568           0.0000                0.0000          0.2871   \n",
       "\n",
       "     worst fractal dimension  \n",
       "0                    0.11890  \n",
       "1                    0.08902  \n",
       "2                    0.08758  \n",
       "3                    0.17300  \n",
       "4                    0.07678  \n",
       "..                       ...  \n",
       "564                  0.07115  \n",
       "565                  0.06637  \n",
       "566                  0.07820  \n",
       "567                  0.12400  \n",
       "568                  0.07039  \n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(X, columns=breast_cancer.feature_names)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. División del conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del conjunto de datos de entrenamiento:  426\n",
      "Tamaño del conjunto de datos de pruebas:  143\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#el parametro stratify se encarga de mantener las proporciones en los conjuntos de datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, Y, stratify=Y)\n",
    "\n",
    "print(\"Tamaño del conjunto de datos de entrenamiento: \", len(X_train))\n",
    "print(\"Tamaño del conjunto de datos de pruebas: \", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Implementación de una MPNeuron más avanzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class MPNeuron:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.threshold = None\n",
    "        \n",
    "    def model(self, x):\n",
    "        return (sum(x) >= self.threshold)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        Y = []\n",
    "        for x in X:\n",
    "            result = self.model(x)\n",
    "            Y.append(result)\n",
    "        return np.array(Y)\n",
    "        \n",
    "    #este metodo se encarga de encontrar el valor del threshold que mejro se adapta al cnojinto de datos\n",
    "    def fit(self, X, Y):\n",
    "        accuracy = {}\n",
    "        # Seleccionamos un threshold entre el # de características de entrada\n",
    "        for th in range(X.shape[1] + 1):\n",
    "            self.threshold = th\n",
    "            Y_pred = self.predict(X)\n",
    "            accuracy[th] = accuracy_score(Y_pred, Y)\n",
    "        # Seleccionamos el threshold que mejores resultados proporciona\n",
    "        self.threshold = max(accuracy, key=accuracy.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seguimos teniendo un problema debido a que en nuestro conjunto de datos las características de entrada reciben valores continuos, sin embargo, nuestra MPNeuron solo procesa características de entrada con valor binario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 1, 1, 1, 0, 0]\n",
      "Categories (2, int64): [0 < 1]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Para transformar un valor a binario\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(pd.cut([0.04, 2, 4, 5, 6, 0.02, 0.6], bins=2, labels=[0, 1]))\n",
    "\n",
    "plt.hist([0.04, 0.3, 4, 5, 6, 0.02, 0.6], bins=2) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>426 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean radius mean texture mean perimeter mean area mean smoothness  \\\n",
       "360           1            1              1         1               1   \n",
       "303           1            1              1         1               1   \n",
       "487           0            1              0         1               0   \n",
       "196           1            1              1         1               0   \n",
       "394           1            1              1         1               1   \n",
       "..          ...          ...            ...       ...             ...   \n",
       "228           1            1              1         1               1   \n",
       "309           1            1              1         1               1   \n",
       "199           1            1              1         1               1   \n",
       "58            1            1              1         1               1   \n",
       "434           1            1              1         1               1   \n",
       "\n",
       "    mean compactness mean concavity mean concave points mean symmetry  \\\n",
       "360                1              1                   1             1   \n",
       "303                1              1                   1             1   \n",
       "487                1              0                   0             1   \n",
       "196                1              1                   1             1   \n",
       "394                1              1                   1             1   \n",
       "..               ...            ...                 ...           ...   \n",
       "228                1              1                   1             1   \n",
       "309                1              1                   1             1   \n",
       "199                1              1                   1             1   \n",
       "58                 1              1                   1             1   \n",
       "434                1              1                   1             1   \n",
       "\n",
       "    mean fractal dimension  ... worst radius worst texture worst perimeter  \\\n",
       "360                      1  ...            1             1               1   \n",
       "303                      1  ...            1             1               1   \n",
       "487                      1  ...            0             1               0   \n",
       "196                      1  ...            1             0               1   \n",
       "394                      1  ...            1             1               1   \n",
       "..                     ...  ...          ...           ...             ...   \n",
       "228                      1  ...            1             0               1   \n",
       "309                      1  ...            1             1               1   \n",
       "199                      1  ...            1             1               1   \n",
       "58                       1  ...            1             1               1   \n",
       "434                      1  ...            1             1               1   \n",
       "\n",
       "    worst area worst smoothness worst compactness worst concavity  \\\n",
       "360          1                1                 1               1   \n",
       "303          1                1                 1               1   \n",
       "487          1                0                 1               1   \n",
       "196          1                0                 1               1   \n",
       "394          1                1                 1               1   \n",
       "..         ...              ...               ...             ...   \n",
       "228          1                1                 1               1   \n",
       "309          1                1                 1               1   \n",
       "199          1                0                 1               1   \n",
       "58           1                1                 1               1   \n",
       "434          1                1                 1               1   \n",
       "\n",
       "    worst concave points worst symmetry worst fractal dimension  \n",
       "360                    1              1                       1  \n",
       "303                    1              1                       1  \n",
       "487                    0              1                       1  \n",
       "196                    0              1                       1  \n",
       "394                    1              1                       1  \n",
       "..                   ...            ...                     ...  \n",
       "228                    1              1                       1  \n",
       "309                    1              1                       1  \n",
       "199                    0              0                       1  \n",
       "58                     1              1                       1  \n",
       "434                    1              1                       1  \n",
       "\n",
       "[426 rows x 30 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transformamos las caracteríticas de entrada a un valor binario\n",
    "#apply aplica una funciona  todo el conjunto de datos\n",
    "X_train_bin = X_train.apply(pd.cut, bins=2, labels=[1, 0])\n",
    "X_test_bin = X_test.apply(pd.cut, bins=2, labels=[1, 0])\n",
    "\n",
    "X_train_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciamos el modelo MPNeuron\n",
    "mp_neuron = MPNeuron()\n",
    "\n",
    "# Encontramos el threshold óptimo (con el conjujnto de datos de entrenamiento)\n",
    "mp_neuron.fit(X_train_bin.to_numpy(), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Threshold óptimo seleccionado\n",
    "mp_neuron.threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizamos predicciones para ejemplos nuevos que no se encuentran en el conjunto de datos de entrenamiento\n",
    "Y_pred = mp_neuron.predict(X_test_bin.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True, False, False,  True,  True,  True,  True, False,\n",
       "        True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "       False, False, False, False,  True, False,  True,  True,  True,\n",
       "        True,  True,  True, False,  True,  True, False, False, False,\n",
       "       False,  True, False,  True,  True, False,  True,  True,  True,\n",
       "       False,  True, False,  True,  True,  True, False, False,  True,\n",
       "       False, False,  True,  True,  True, False, False,  True, False,\n",
       "       False,  True,  True, False, False,  True,  True,  True,  True,\n",
       "       False, False, False, False, False, False,  True,  True,  True,\n",
       "        True,  True, False,  True,  True, False,  True,  True,  True,\n",
       "       False,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True, False,  True,  True,  True, False, False, False,\n",
       "        True, False,  True, False,  True,  True,  True, False, False,\n",
       "        True,  True, False,  True,  True, False, False,  True])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8741258741258742"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculamos la exactitud de nuestra predicción\n",
    "accuracy_score(y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[43, 10],\n",
       "       [ 8, 82]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculamos la matriz de confusión, indica los verdaderos positivoss, verdaderos negativos, falsos negativos y falsos positivos\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
